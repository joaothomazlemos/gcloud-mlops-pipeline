timeout: 3600s
logsBucket: gs://first-bucket-ml/cloudbuild-logs
substitutions:
  _BUCKET_NAME: first-bucket-ml
  _RAW_DATA_GCS_URI: gs://first-bucket-ml/churn.csv
  _BQ_PROJECT_ID: vocal-day-462221-r6
  _BQ_DATASET_NAME: churn_ml_feature_store
  _BQ_FEATURE_TABLE: vocal-day-462221-r6.churn_ml_feature_store.churn_features
  _MODEL_ARTIFACT_GCS_DIR: gs://vocal-day-462221-r6-ml-models/churn_predictor_$BUILD_ID
  _MODEL_NAME_REGISTRY: customer_churn_predictor_model
  _ENDPOINT_DISPLAY_NAME: churn-prediction-endpoint
  _REGION: us-east1
  _K6_VM_NAME: churn-k6-load-gen-$BUILD_ID
  _K6_REGION: us-east1
  _MONITORING_EMAIL: joaothomazlemos@gmail.com
steps:
  - id: Verify Raw Data in GCS
    name: gcr.io/cloud-builders/gsutil
    entrypoint: bash
    args:
      - -c
      - >
        echo "Checking for raw data file: ${_RAW_DATA_GCS_URI}"

        gsutil ls "${_RAW_DATA_GCS_URI}" || { echo "Raw data file NOT FOUND. Please upload 'Customer Churn.csv' to '${_RAW_DATA_GCS_URI}'"; exit 1; }

        echo "Raw data file found."
  - id: Build Training Docker Image
    name: gcr.io/cloud-builders/docker
    args:
      - build
      - -t
      - gcr.io/$PROJECT_ID/churn-trainer:latest
      - .
    dir: trainer/
  - id: Push Training Docker Image
    name: gcr.io/cloud-builders/docker
    args:
      - push
      - gcr.io/$PROJECT_ID/churn-trainer:latest
    waitFor:
      - Build Training Docker Image
  - id: Run Integration Tests
    name: gcr.io/$PROJECT_ID/churn-trainer:latest
    entrypoint: pytest
    args:
      - train/tests/integration/
    waitFor:
      - Push Training Docker Image
  - id: Train Model
    name: gcr.io/$PROJECT_ID/churn-trainer:latest
    args:
      - python
      - train/train.py
      - --bq-table-id=${_BQ_FEATURE_TABLE}
      - --model-output-dir=/workspace/model_output
    env:
      - AIP_MODEL_DIR=/workspace/model_output
    waitFor:
      - Run Integration Tests
      - Run PySpark ETL to BigQuery
  - id: Upload Trained Model to GCS
    name: gcr.io/cloud-builders/gsutil
    args:
      - cp
      - -r
      - /workspace/model_output/*
      - ${_MODEL_ARTIFACT_GCS_DIR}/
    waitFor:
      - Train Model
  - id: Upload Model to Vertex AI Registry
    name: gcr.io/cloud-builders/gcloud
    args:
      - beta
      - ai
      - models
      - upload
      - --display-name=${_MODEL_NAME_REGISTRY}
      - --project=$PROJECT_ID
      - --region=${_REGION}
      - --artifact-uri=${_MODEL_ARTIFACT_GCS_DIR}
      - --container-image-uri=us-docker.pkg.dev/cloud-aiplatform/prediction/sklearn-cpu.1-0:latest
      - --sync
    waitFor:
      - Upload Trained Model to GCS
  - id: Get Model ID
    name: ubuntu
    entrypoint: bash
    args:
      - -c
      - >
        MODEL_ID=$(gcloud beta ai models list
        --filter="displayName=${_MODEL_NAME_REGISTRY}" --format="value(name)"
        --sort-by="createTime" --limit=1 --project=$PROJECT_ID
        --region=${_REGION})

        echo "export MODEL_ID=$$MODEL_ID" > /workspace/model_id.env
    waitFor:
      - Upload Model to Vertex AI Registry
  - id: Get or Create Endpoint ID
    name: ubuntu
    entrypoint: bash
    args:
      - -c
      - >
        ENDPOINT_ID=$(gcloud beta ai endpoints list
        --filter="displayName=${_ENDPOINT_DISPLAY_NAME}" --format="value(name)"
        --limit=1 --project=$PROJECT_ID --region=${_REGION})

        if [ -z "$$ENDPOINT_ID" ]; then
          echo "Endpoint not found. Creating new endpoint..."
          ENDPOINT_CREATE_RESPONSE=$(gcloud beta ai endpoints create --display-name=${_ENDPOINT_DISPLAY_NAME} --project=$PROJECT_ID --region=${_REGION} --format="json")
          ENDPOINT_ID=$(echo "$ENDPOINT_CREATE_RESPONSE" | jq -r '.name')
          echo "New endpoint created: $$ENDPOINT_ID"
        else
          echo "Found existing endpoint: $$ENDPOINT_ID"
        fi

        echo "export ENDPOINT_ID=$$ENDPOINT_ID" > /workspace/endpoint_id.env
    waitFor:
      - Get Model ID
  - id: Deploy Model to Vertex AI Endpoint
    name: gcr.io/cloud-builders/gcloud
    entrypoint: bash
    args:
      - -c
      - >
        source /workspace/model_id.env

        source /workspace/endpoint_id.env

        echo "Deploying model $$MODEL_ID to endpoint $$ENDPOINT_ID"

        gcloud beta ai endpoints deploy-model $$ENDPOINT_ID \
          --model=$$MODEL_ID \
          --display-name=${_MODEL_NAME_REGISTRY}-deployed \
          --machine-type=n1-standard-2 \
          --accelerator=count=0 \
          --traffic-split=0=100 \
          --project=$PROJECT_ID \
          --region=${_REGION} \
          --sync
        # Capture deployed model ID for monitoring setup

        DEPLOYED_MODEL_ID=$(gcloud beta ai endpoints describe $$ENDPOINT_ID --format="value(deployedModels[0].id)" --project=$PROJECT_ID --region=${_REGION})

        echo "export DEPLOYED_MODEL_ID=$$DEPLOYED_MODEL_ID" >> /workspace/endpoint_id.env
    waitFor:
      - Get or Create Endpoint ID
  - id: Configure Vertex AI Model Monitoring
    name: gcr.io/cloud-builders/gcloud
    entrypoint: bash
    args:
      - -c
      - >
        source /workspace/model_id.env

        source /workspace/endpoint_id.env

        echo "Configuring monitoring for endpoint $$ENDPOINT_ID, model $$MODEL_ID"

        gcloud beta ai model-monitoring-jobs create \
          --display-name=churn_data_drift_monitor \
          --project=$PROJECT_ID \
          --region=${_REGION} \
          --endpoint=projects/$PROJECT_ID/locations/${_REGION}/endpoints/$$ENDPOINT_ID \
          --feature-attributions-skew-detection-logging-sampling-rate=0.1 \
          --feature-attributions-drift-detection-logging-sampling-rate=0.1 \
          --data-source-bq-table=${_BQ_FEATURE_TABLE} \
          --model-monitoring-alert-config-email-addresses=${_MONITORING_EMAIL} \
          --model-monitoring-alert-config-enable-email-alerting \
          --logging-sampling-rate=0.1 \
          --predict-instance-schema-uri=gs://cloud-aiplatform/schema/predict/instance/tabular_classification_1.0.yaml \
          --schedule-interval=24h \
          --enable-dashboard \
          --model=$$MODEL_ID
    waitFor:
      - Deploy Model to Vertex AI Endpoint
